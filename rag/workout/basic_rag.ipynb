{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37mGowzAOn8g"
      },
      "outputs": [],
      "source": [
        "!pip install \"transformers>=4.47.1,<5.0.0\"\n",
        "!pip install \"flash-attn>=2.6.3,<2.8\" --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHPorx0b007E",
        "outputId": "4678d23d-8cff-4072-fcb0-5993529296c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from safetensors.torch import save_file, load_file\n",
        "import torch\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoProcessor, Qwen3VLForConditionalGeneration\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"[INFO] Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Hl3lFrqXp67d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_dataset(path=\"/content/megaGymDataset.csv\"):\n",
        "  df = pd.read_csv(path)\n",
        "\n",
        "  df = df.drop(columns=[\"Unnamed: 0\"], errors=\"ignore\")\n",
        "\n",
        "  df = df.fillna(\"\")\n",
        "\n",
        "  df = df.astype(str)\n",
        "\n",
        "  columns = df.columns.tolist()\n",
        "\n",
        "  df[\"data\"] = df.apply(\n",
        "      lambda row: (\n",
        "          f\"Exercise: {row['Title']}. \\n\"\n",
        "          f\"Description: {row['Desc']}. \\n\"\n",
        "          f\"Type: {row['Type']}. \\n\"\n",
        "          f\"Target Muscle: {row['BodyPart']}. \\n\"\n",
        "          f\"Equipment: {row['Equipment']}. \\n\"\n",
        "          f\"Level: {row['Level']}.\"\n",
        "      ),\n",
        "      axis=1\n",
        "  )\n",
        "\n",
        "  dataset = df[[\"data\"]]\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "b2b71ac969ef441f963e524b8c74bb7f",
            "51618074feff4a4ba2828133cb7f041a",
            "fc847734adc94d52a4b2bf1c10ce48cd",
            "1b9976deef994bcf9f9a51af3ffd226c",
            "6052ffbb4a964302b2b2a8d3c98e0476",
            "00fcdfdf13c54c68b5ca81d8bb7810f8",
            "a364a889260241058a2249a25cb070a2",
            "291bbfe9f93245198a868c0074533920",
            "76a95ea4c68b48429e047fc8afbcfc5e",
            "fcfdfd03305242c893037a91d702555f",
            "036a818066854a7e8d646f287b0c750e"
          ]
        },
        "id": "svDbCYGtaHaX",
        "outputId": "28758912-9965-47cc-d101-8d0d7e4b78d6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2b71ac969ef441f963e524b8c74bb7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "processing_llama_nemotron_vl.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/nvidia/llama-nemotron-embed-vl-1b-v2:\n",
            "- processing_llama_nemotron_vl.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Loaded model: Qwen/Qwen3-VL-2B-Instruct\n",
            "[INFO] Device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Note: The extra commit hashes are required to run the models without flash_attention_2\n",
        "EMBED_MODEL_PATH = \"nvidia/llama-nemotron-embed-vl-1b-v2\"\n",
        "EMBED_COMMIT_HASH = \"5b5ca69c35bf6ec1484d2d5ff238626e67a745e2\"\n",
        "\n",
        "# Load Embedding Model\n",
        "embed_model = AutoModel.from_pretrained(\n",
        "    EMBED_MODEL_PATH,\n",
        "    revision=EMBED_COMMIT_HASH,\n",
        "    dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    device_map=\"auto\",\n",
        ").eval()\n",
        "\n",
        "embed_model.processor.p_max_length = 8192\n",
        "embed_model.processor.max_input_tiles = 6\n",
        "embed_model.processor.use_thumbnail = True\n",
        "\n",
        "\n",
        "# Load Qwen3-VL-2B model and processor\n",
        "GENERATION_MODEL_ID = \"Qwen/Qwen3-VL-2B-Instruct\"\n",
        "\n",
        "qwen_model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
        "    GENERATION_MODEL_ID,\n",
        "    dtype=\"auto\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "qwen_processor = AutoProcessor.from_pretrained(GENERATION_MODEL_ID)\n",
        "\n",
        "print(f\"[INFO] Loaded model: {GENERATION_MODEL_ID}\")\n",
        "print(f\"[INFO] Device: {qwen_model.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "X3L2MvTOshq1"
      },
      "outputs": [],
      "source": [
        "def get_text_embedding(df):\n",
        "  BATCH_SIZE = 8  # keep consistent\n",
        "  PATH_TO_EMBEDDING_FILE=\"/content/text_embedding.safetensors\"\n",
        "\n",
        "  if os.path.exists(PATH_TO_EMBEDDING_FILE):\n",
        "    text_embeddings = load_file(PATH_TO_EMBEDDING_FILE)\n",
        "    text_embeddings = text_embeddings[\"text_embeddings\"].to(DEVICE)\n",
        "  else:\n",
        "    text_embeddings = []\n",
        "\n",
        "    for i in tqdm(range(0, len(df), BATCH_SIZE), desc=\"Embedding text\"):\n",
        "        dataset_chunk = df.iloc[i:i+BATCH_SIZE]\n",
        "        texts_to_embed = dataset_chunk[\"data\"].tolist()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            text_embed_chunk = embed_model.encode_documents(texts=texts_to_embed)\n",
        "\n",
        "        text_embeddings.append(text_embed_chunk)\n",
        "\n",
        "    text_embeddings = torch.cat(text_embeddings, dim=0)\n",
        "    save_file({\"text_embeddings\": text_embeddings}, PATH_TO_EMBEDDING_FILE)\n",
        "\n",
        "  return text_embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qXrObWPgwZ1Z"
      },
      "outputs": [],
      "source": [
        "def _l2_normalize(x: torch.Tensor, eps: float = 1e-12) -> torch.Tensor:\n",
        "    return x / (x.norm(p=2, dim=-1, keepdim=True) + eps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3jnrfBK4whNd"
      },
      "outputs": [],
      "source": [
        "def match_query_to_embeddings(query: str,\n",
        "                              target_embeddings_to_match: torch.Tensor,\n",
        "                              top_k: int = 100) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "\n",
        "    with torch.inference_mode():\n",
        "      query_embeddings = embed_model.encode_queries([query])\n",
        "\n",
        "    # Compute cosine similarity (use cosine for normalized tensors)\n",
        "    cos_sim = _l2_normalize(query_embeddings) @ _l2_normalize(target_embeddings_to_match).T\n",
        "\n",
        "    # Flatten logits the 1D array (handle both [batch_size] and [batch_size, 1] shapes)\n",
        "    cos_sim_flat = cos_sim.flatten()\n",
        "\n",
        "    # Sort the indices\n",
        "    sorted_indices = torch.argsort(cos_sim_flat, descending=True)[:top_k]\n",
        "\n",
        "    # Get the top scores (sort by the top indicies)\n",
        "    sorted_scores = cos_sim_flat[sorted_indices][:top_k]\n",
        "\n",
        "    return sorted_scores, sorted_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "n8Xzyq-nfaVt"
      },
      "outputs": [],
      "source": [
        "def generate_workout_summary(\n",
        "    workout_texts: list[str],\n",
        "    model: Qwen3VLForConditionalGeneration = qwen_model,\n",
        "    processor: AutoProcessor = qwen_processor,\n",
        "    max_new_tokens: int = 512\n",
        "  ) -> str:\n",
        "  workout_combined = \"\"\n",
        "  for i, workout in enumerate(workout_texts[:3]):\n",
        "    workout_combined += f\"\\n \\n--- Exercise {i+1} ---\\n{workout}\"\n",
        "\n",
        "  prompt = f\"\"\"Your a helpful workout trainer. Below are the {len(workout_texts[:3])} workouts.\n",
        "  Please provide a brief markdown summary with:\n",
        "- A short 1-2 sentence overview of each workout\n",
        "- Key training method highlighted\n",
        "- Estimated difficulty (Beignner/Intermediate/Advanced)\n",
        "- Which workout might be best for a good workout session\n",
        "For example use the following format:\n",
        "\n",
        "```markdown\n",
        "# Workout summary\n",
        "\n",
        "## <workout_name>\n",
        "\n",
        "[details]\n",
        "\n",
        "## <workout_name>\n",
        "\n",
        "[details]\n",
        "\n",
        "## <workout_name>\n",
        "\n",
        "[details]\n",
        "```\n",
        "\n",
        "Keep the summary concise and well-formatted in markdown. Return in ```markdown``` tags so it can be easily parsed.\n",
        "\n",
        "<workouts>\n",
        "{workout_combined}\n",
        "</recipes>\n",
        "\n",
        "## Summary:\n",
        "  \"\"\"\n",
        "\n",
        "  messages = [\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": [\n",
        "              {\"type\": \"text\", \"text\": prompt}\n",
        "          ]\n",
        "      }\n",
        "  ]\n",
        "\n",
        "  inputs = processor.apply_chat_template(\n",
        "      messages,\n",
        "      tokenize=True,\n",
        "      add_generation_prompt=True,\n",
        "      return_dict=True,\n",
        "      return_tensors=\"pt\"\n",
        "  )\n",
        "  inputs = inputs.to(model.device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      generated_ids = model.generate(\n",
        "          **inputs,\n",
        "          max_new_tokens=max_new_tokens,\n",
        "          do_sample=True,\n",
        "          temperature=0.7,\n",
        "          top_p=0.9\n",
        "      )\n",
        "\n",
        "  generated_ids_trimmed = [\n",
        "       out_ids[len(in_ids):]\n",
        "        for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "  ]\n",
        "\n",
        "  output_text = processor.batch_decode(\n",
        "      generated_ids_trimmed,\n",
        "      skip_special_tokens=True,\n",
        "      clean_up_tokenization_spaces=False\n",
        "  )[0]\n",
        "\n",
        "  return output_text.strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLuq0iQli-tr",
        "outputId": "1c106c98-73ad-401b-935b-87e67a1e6f85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```markdown\n",
            "# Workout summary\n",
            "\n",
            "## Reverse Crunch\n",
            "\n",
            "The reverse crunch targets the lower abdominals and is a beginner-friendly strength exercise performed on the floor or bench. It's ideal for building core stability and is suitable for intermediate lifters.\n",
            "\n",
            "Key training method: Core strength training  \n",
            "Estimated difficulty: Intermediate  \n",
            "Best for: A good workout session when focused on lower abdominal development\n",
            "\n",
            "## Ab Wheel Roll-Out\n",
            "\n",
            "This exercise uses a wheel device to target the abdominal muscles, particularly the transverse abdominis. It's a strength-focused movement that enhances core endurance and stability. \n",
            "\n",
            "Key training method: Core strength training  \n",
            "Estimated difficulty: Intermediate  \n",
            "Best for: A good workout session when targeting midsection strength\n",
            "\n",
            "## Ab Roller\n",
            "\n",
            "The ab roller is a versatile tool for building core strength, especially for the lower abdomen. It offers a full range of motion and is great for building endurance. \n",
            "\n",
            "Key training method: Core strength training  \n",
            "Estimated difficulty: Intermediate  \n",
            "Best for: A good workout session when focusing on core endurance and stability\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "#pass the csv path here: get_dataset('./megaGymDataset.csv')\n",
        "dataset = get_dataset()\n",
        "query = \"beginner friendly abs workout\"\n",
        "text_embeddings = get_text_embedding(dataset)\n",
        "result_sorted_scores, result_sorted_indices = match_query_to_embeddings(query=query,\n",
        "                                                                        target_embeddings_to_match=text_embeddings,\n",
        "                                                                        top_k=100)\n",
        "\n",
        "workout_texts = [dataset.iloc[result_sorted_indices[i].item()][\"data\"]for i in range(3)]\n",
        "result = generate_workout_summary(workout_texts)\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00fcdfdf13c54c68b5ca81d8bb7810f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "036a818066854a7e8d646f287b0c750e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b9976deef994bcf9f9a51af3ffd226c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcfdfd03305242c893037a91d702555f",
            "placeholder": "​",
            "style": "IPY_MODEL_036a818066854a7e8d646f287b0c750e",
            "value": " 19.3k/? [00:00&lt;00:00, 1.07MB/s]"
          }
        },
        "291bbfe9f93245198a868c0074533920": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "51618074feff4a4ba2828133cb7f041a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00fcdfdf13c54c68b5ca81d8bb7810f8",
            "placeholder": "​",
            "style": "IPY_MODEL_a364a889260241058a2249a25cb070a2",
            "value": "processing_llama_nemotron_vl.py: "
          }
        },
        "6052ffbb4a964302b2b2a8d3c98e0476": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76a95ea4c68b48429e047fc8afbcfc5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a364a889260241058a2249a25cb070a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2b71ac969ef441f963e524b8c74bb7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51618074feff4a4ba2828133cb7f041a",
              "IPY_MODEL_fc847734adc94d52a4b2bf1c10ce48cd",
              "IPY_MODEL_1b9976deef994bcf9f9a51af3ffd226c"
            ],
            "layout": "IPY_MODEL_6052ffbb4a964302b2b2a8d3c98e0476"
          }
        },
        "fc847734adc94d52a4b2bf1c10ce48cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_291bbfe9f93245198a868c0074533920",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76a95ea4c68b48429e047fc8afbcfc5e",
            "value": 1
          }
        },
        "fcfdfd03305242c893037a91d702555f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
