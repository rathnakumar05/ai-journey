{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d68b81f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from cnn_utils import train, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be8c462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "dtype = torch.float32\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "torch.set_default_device(device)\n",
    "torch.manual_seed(seed)\n",
    "generator = torch.Generator(device=device).manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "749bfe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# ds = load_dataset(\"slegroux/tiny-imagenet-200-clean\")\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# def transform_ds(batch):\n",
    "#     batch[\"image\"] = [transform(img) for img in batch[\"image\"]]\n",
    "#     return batch\n",
    "\n",
    "# dataset = ds.with_transform(lambda x: transform_ds(x))\n",
    "\n",
    "# train_dataset = dataset[\"train\"]\n",
    "# test_dataset = dataset[\"test\"]\n",
    "# val_dataset = dataset['validation']\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, generator=generator)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, generator=generator)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "103dea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.FashionMNIST(root = './cnn_dataset',\n",
    "                                               train = True,\n",
    "                                               transform = transforms.Compose([\n",
    "                                                   transforms.Resize((224, 224)),\n",
    "                                                   transforms.ToTensor(),\n",
    "                                               ]),\n",
    "                                               download = True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root = './cnn_dataset',\n",
    "                                               train = False,\n",
    "                                               transform = transforms.Compose([\n",
    "                                                   transforms.Resize((224, 224)),\n",
    "                                                   transforms.ToTensor(),\n",
    "                                               ]),\n",
    "                                               download = True)\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.8)\n",
    "val_size = int(total_size * 0.2)\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, generator=generator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, generator=generator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebcabedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.LazyConv2d(96, kernel_size=11, stride=4, padding=1),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LazyConv2d(256, kernel_size=5, padding=2), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LazyConv2d(384, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.LazyConv2d(384, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.LazyConv2d(256, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), \n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(4096), nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efd667a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.6034610393817226 valid 0.3610554906129837\n",
      "LOSS train 0.3395211027910312 valid 0.3240429779291153\n",
      "LOSS train 0.29169135929147405 valid 0.26630316814780236\n",
      "LOSS train 0.2642030742950737 valid 0.2707809422214826\n",
      "LOSS train 0.2424084764290601 valid 0.25179985917111236\n",
      "LOSS train 0.2225952960724632 valid 0.24312122026085853\n",
      "LOSS train 0.21314185327912372 valid 0.2504298675159613\n",
      "LOSS train 0.19616748427599667 valid 0.24498437702655793\n",
      "LOSS train 0.188476123607407 valid 0.2465942451407512\n",
      "LOSS train 0.1779531557255735 valid 0.24714284587651492\n",
      "LOSS train 0.17037369275527695 valid 0.23077028650417925\n",
      "LOSS train 0.16452303640979032 valid 0.24053801298886537\n",
      "LOSS train 0.15673319793174353 valid 0.23364908490578334\n",
      "LOSS train 0.15039672307825336 valid 0.2563107480679949\n",
      "LOSS train 0.14203970025091742 valid 0.2765418252547582\n",
      "LOSS train 0.13898530744807794 valid 0.2457275699774424\n",
      "LOSS train 0.12946846306494747 valid 0.26464771291986106\n",
      "LOSS train 0.12744115247391163 valid 0.2862183953821659\n",
      "LOSS train 0.12141955005881998 valid 0.23798767441759508\n",
      "LOSS train 0.11777721016120632 valid 0.29099763367821774\n",
      "ACC 0.9085\n"
     ]
    }
   ],
   "source": [
    "output_size = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = AlexNet(output_size)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "config = {\n",
    "    \"epoch\" : 20,\n",
    "    \"print_per_epoch\": 1,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "train(model, criterion, optimizer, train_loader, val_loader, config)\n",
    "acc = accuracy(model, test_loader, device)\n",
    "\n",
    "print('ACC {}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
