{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68b81f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from cnn_utils import train, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be8c462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "dtype = torch.float32\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "torch.set_default_device(device)\n",
    "torch.manual_seed(seed)\n",
    "generator = torch.Generator(device=device).manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "749bfe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(root = './cnn_dataset',\n",
    "                                               train = True,\n",
    "                                               transform = transforms.ToTensor(),\n",
    "                                               download = True)\n",
    "test_dataset = torchvision.datasets.MNIST(root = './cnn_dataset',\n",
    "                                               train = False,\n",
    "                                               transform = transforms.ToTensor(),\n",
    "                                               download = True)\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.8)\n",
    "val_size = int(total_size * 0.2)\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, generator=generator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, generator=generator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebcabedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5, padding=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.LazyLinear(84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.LazyLinear(num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd667a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.24041746968651811 valid 0.20754111501574515\n",
      "LOSS train 0.11815097906067967 valid 0.11709891218940417\n",
      "LOSS train 0.08561533959023654 valid 0.08392027513186137\n",
      "LOSS train 0.07073079738890131 valid 0.0779736869049569\n",
      "LOSS train 0.06242267719112957 valid 0.07903549768651526\n",
      "LOSS train 0.05849538954766467 valid 0.07341436232191821\n",
      "LOSS train 0.054217027234689644 valid 0.0632495189147691\n",
      "LOSS train 0.05231701295915991 valid 0.06130173058869938\n",
      "LOSS train 0.051187940732731176 valid 0.0549211854878813\n",
      "LOSS train 0.0476602442082949 valid 0.07479409708703558\n",
      "ACC 0.981\n"
     ]
    }
   ],
   "source": [
    "output_size = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = LeNet(output_size)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "config = {\n",
    "    \"epoch\" : 20,\n",
    "    \"print_per_epoch\": 2,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "train(model, criterion, optimizer, train_loader, val_loader, config)\n",
    "acc = accuracy(model, test_loader, device)\n",
    "\n",
    "print('ACC {}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
